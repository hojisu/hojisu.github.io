<script> MathJax.Hub.Queue(["Typeset",MathJax.Hub]); </script>

# 검정과 유의확률

### Summary

- 검정은 데이터 뒤에 숨어있는 확률변수의 분포와 모수에 대한 가설의 진위를 정량적으로 증명하는 작업니다. 
- 검정통계량(test statistics)은 표본 데이터 집합을 입력으로 계산되는 함수의 값. 기호 $$t$$ 로 나타낸다.
- 분산 모수 $$\sigma^2$$의  값을 알고 있는 정규 분포 확률변수에 대해서는 다음과 같이 샘플 평균을 정규화(nomarlize)한 값을 검정통계량으로 쓴다. 이 검정통계량은 표준 정규 분포를 따른다. 이 검정통계량은 특별히 $$𝑧$$라고 부른다.
- 평균 모수 $$\mu$$  에 대한 검정을 할 때는 다음과 같이 샘플 평균을 샘플 분산으로 정규화(nomarlize)한 값을 검정통계량으로 쓴다. 이 검정통계량은 자유도가 $$𝑁−1$$인 표준 student-t 분포를 따른다. $$𝑁$$은 데이터의 수이다.
- 자유도란 평균과 같은 통계값은 모집단에 대해 불편 추정된다. (클수도 있고 작을수도 있다는 것) 하지만 분산의 경우, 자료를 제곱하기 때문에 자료의 크기가 작을수록 분산이 낮아지게 된다. 즉 수학적으로 편향 추정된다는 것이다. (모집단에 비해 작음) 이러한 편향 추정을 보정하기 위해 표본 자료의 분산에 n/n-1 을 곱하게 되면 모집단과 유사한 값을 가지게 된다. 이름이 자유도인 이유는, 마지막 한 개는 모집단의 통계값과 같아지기 위해 사용되므로 자유를 상실하기 때문이다.
- p-value(유의확률)은 어떤 표본 데이터가 해당 확률분포에서 나오기 쉬운값인지 어려운값인지 숫자로 정량화한 값이다. 검정 관점에서 p-value는 귀무가설이 맞음에도 불구하고 현재 검정통계량값과 같은 혹은 대립가설을 더 옹호하는 검정통계량값이 나올 확률이다. 만약 p-value가 너무 낮으면, 가설이 일어날 확률이 너무 낮기 때문에 귀무가설을 기각하게 된다. 보통 그 기준은 정하기 나름이지만 일반적인 사회통계학에서는 0.05나 0.01을 기준으로 한다. 이 기준을 바로 유의수준이라고 한다.
- 제 1종 오류는 옳은 가설이 거부될 때 생기고 제 2종 오류는 잘못된 가설이 채택될 때 생긴다.
_________________

### 가설과 검정

**가설(hypothesis)**은 확률분포에 대한 어떤 주장이다. $$H$$ 로 표기한다.
**통계적 가설 검정(statistical hypothesis testing)**은 가설을 증명하는 행위로 줄여서 **검정(testing)** 이라고 한다.
**모수 검정(parameter testing)**은 확률분포의 모수 값이 특정한 값을 가진다는 가설을 검정하는 것이다.

### 귀무가설

검정을 작업을 하기 위해서는 데이터가 어떤 확률변수의 포본이라고 가정한다. 데이터를 만드는 확률변수가 따르는 확률분포의 모수 $$\theta$$ 의 값이 어떤 특정한 실수 값 $$\theta_0$$ 으로 **고정** 되어 있다고 가정한다.

**귀무가설(null hypothesis)**은 확률분포의 모수에 대한 가설이다. $$H_0$$ 으로 표기한다.

귀무가설은 확률분포를 특정한 상태로 **고정** 시켜야 하므로 반드시 **등식(equality)** 로 표현되어야 한다. 특정한 실수 값 $$\theta_0$$ 는 우리가 증명하고자 하는 가설에 대한 기준값이 되는 상수를 사용한다.

$$
H_0: \theta = \theta_0
$$

### 대립가설

**대립가설(alternative hypothesis)** 은 귀무가설과 같이 고려해야하는 가설이다. 기호로 $$H_a$$ 로 표기한다. 대립가설을 **연구가설(research hypothesis)** 이라고도 한다. 대부분 경우 진실임을 증명하고자 하는 가설을 대립가설로 놓는 경우가 많다.

- 귀무가설이 거짓이라는 것이 증명되면 대립가설은 사실
- 귀무가설이 거짓이 아니라면 대립가설이 거짓

예를 들어 모수 $$\theta$$ 가 어떤 특정한 값 $$\theta_0$$ 가 아니라는 것을 증명하고 싶다면 귀무가설과 대립가설은 다음과 같다.

$$
H_0: \theta = \theta_0 ,\;\;\; H_a: \theta \neq \theta_0
$$

$$\theta$$ 가 $$\theta_0$$ 보다 크다는 것을 증명하고 싶다면 귀무가설과 대립가설은 다음과 같다.

$$
H_0: \theta = \theta_0, \;\;\; H_a: \theta > \theta_0
$$

귀무가설과 대립가설이 반드시 서로 여집합(complement)의 관계에 있을 필요는 없다.

### 검정통계량

**검정통계량(test statistics)** 은 표본 데이터 집합을 입력으로 계산되는 함수의 값이다. 기호 $$t$$ 로 나타낸다.

$$
t = f(x_1, x_2, \ldots, x_N)
$$

검정통계량 $$t$$ 도 **검정통계량 확률변수 $$T$$** 라는 새로운 확률변수의 표본으로 볼 수 있다.

**입력 데이터가 되는 확률변수 $$𝑋$$의 확률분포함수 $$p_X(x)$$와 검정통계량 수식 $$f(x)$$가 이미 결정되어 있기 때문에 검정통계량 확률변수 $$T$$의 확률분포함수 $$p_T(t)$$도 수식으로 유도할 수 있다.**

$$
\left\{
\begin{matrix}
p_X(x) \\
f(x_1, x_2, \ldots, x_N)
\end{matrix}
\right\}
\;\; \rightarrow \;\; p_T(t)
$$



### 일반적으로 많이 사용되는 검정통계량

#### 베르누이 분포 확률변수

모수 $$\mu$$ 를 가지는 베르누이 분포 확률변수에 대해서는 전체 시도 횟수 $$𝑁$$ 번 중 성공한 횟수 $$𝑛$$자체를 검정통계량으로 쓸 수 있다. 이 검정통계량은 자유도 $$𝑁$$과 모수 $$𝜇$$를 가지는 이항 분포를 따른다.

$$
x \sim \text{Bern}  \;\; \rightarrow \;\; t = \sum x \sim \text{Bin}
$$

#### 분산 $$\sigma^2$$ 값을 알고 있는 정규 분포 확률변수

분산 모수 $$\sigma^2$$의  값을 알고 있는 정규 분포 확률변수에 대해서는 다음과 같이 샘플 평균을 정규화(nomarlize)한 값을 검정통계량으로 쓴다. 이 검정통계량은 표준 정규 분포를 따른다. 이 검정통계량은 특별히 $$𝑧$$라고 부른다.

$$
x \sim \mathcal{N}(\mu, \sigma^2) \;\; \rightarrow \;\; z = \dfrac{\bar{x}-\mu}{\frac{\sigma}{\sqrt{N}}} \sim \mathcal{N}(z;0,1)
$$

여기에서 $$\bar{x}$$은 샘플 평균이다.

$$
\bar{x} = \dfrac{1}{N}\sum_{i=1}^{N} x_i
$$

#### 분산 $$\sigma^2$$ 값을 모르는 정규 분포 확률변수

평균 모수 $$\mu$$  에 대한 검정을 할 때는 다음과 같이 샘플 평균을 샘플 분산으로 정규화(nomarlize)한 값을 검정통계량으로 쓴다. 이 검정통계량은 자유도가 $$𝑁−1$$인 표준 student-t 분포를 따른다. $$𝑁$$은 데이터의 수이다.

$$
x \sim \mathcal{N}(\mu, \sigma^2) \;\; \rightarrow \;\; t = \dfrac{m-\mu}{\frac{s}{\sqrt{N}}} \sim t(t;0,1,N-1)
$$

여기에서 $$m$$ 은 샘플 평균이다.

$$
m = \dfrac{1}{N}\sum_{i=1}^{N} x_i
$$

$$s^2$$ 은 샘플 분산이다.

$$
s^2 = \dfrac{1}{N-1}\sum_{i=1}^{N} (x_i-m)^2
$$

분산 모수 $$\sigma^2$$ 에 대한 검정을 할 때는 샘플 분산을 정규화(normalize)한 값을 검정통계량으로 쓴다. 이 검정통계량은 자유도가 $$𝑁−1$$인 카이 제곱 분포를 따른다. $$𝑁$$은 데이터의 수이다.

$$
x \sim \mathcal{N}(\mu, \sigma^2) \;\; \rightarrow \;\; t = (N-1)\dfrac{s^2}{\sigma^2} \sim \chi^2 (t;N-1)
$$


### 유의확률

우리가 최초에 가정한 귀무가설이 사실이라면 실제 데이터에서 구한 검정통계량의 값은 검정통계량 확률분포를 따르고 있으므로 가장 기댓값이나 모드값 근처의 값이 나왔을 것이다. 반대로 우리가 가정한 귀무가설이 사실이 아니라면 실제 데이터에서 구한 검정통계량의 값은 검정통계량에서 나오가 어려운 값, 즉 아웃라이어(outlier)가 나왔을 것이다

**유의확률** 은 확률분포와 확률분포의 표본값 1개가 주어졌을 때 그 확률분포에서 해당 표본값 혹은 더 희귀한(rare) 값이 나올 수 있는 확률을 나타낸다.

유의 확률의 값은 확률밀도함수에서 표본값을 기준으로 만들어진 양측 꼬리(tail)부분에 해당하는 영역의 면적이다.

확률분포가 대칭인 경우에는 누적확률분포함수 $$𝐹(𝑥)$$를 사용하여 다음처럼 계산할 수 있다. 

$$
  \text{p-value} = 
  \begin{cases}
  2F(t_0) & \text{ if } t_0 < \text{mode} \\
  2(1 - F(t_0)) & \text{ if } t_0 > \text{mode} \\
  \end{cases}
$$

$$t_0$$ 는 현재 검정통계량의 값이다.

이산확률분포라면 등호가 성립하는 부분을 제외해야 하므로 다음처럼 구한다.

$$
\text{p-value} = 
  \begin{cases}
  2F(t_0) & \text{ if } t_0 < \text{mode} \\
  2(1 - F(t_0 - 1)) & \text{ if } t_0 > \text{mode} \\
  \end{cases}
$$

확률분포가 비대칭이라면 검정통계량 $$𝑡_0$$와 확률밀도(질량)가 같은 두 검정통계량$$ 𝑡_1,𝑡_2(𝑡_1<𝑡_2)$$를 구하고 다음 식에 대입한다.

$$
\text{p-value} = F(t_1) + (1 - F(t_2))
$$

검정의 관점에서 유의확률은 귀무가설이 맞음에도 불구하고 현재 검정통계량 값과 같은 혹은 대립가설을 더 옹호하는 검정통계량 값이 나올 확률 이라고 본다

$$H_0$$ 은 귀무가설이 진실일 사건을 뜻한다. 
$$
P(t \text{ for } H_a | H_0)
$$

### 단측 유의확률

**단측 유의확률(one-side p-value or one-tail p-value)** 은 만약 증명하고자 하는 대립가설이 부등식인 경우에는 그 대립가설을 옹호하는 검정통계량 값이 나올 확률을 구할 때 특정한 한 방향의 확률만을 구해야 한다. 

만약 모수 $$𝜃$$가 양수라는 것을 증명하고 싶다면 귀무가설과 대립가설은 다음과 같다.

$$
  H_0: \theta = \theta_0, \;\;\; H_a: \theta > \theta_0
$$

만약 모수 $$𝜃$$가 양수일 때 검정통계량도 큰 값이 나오기 쉬운 경우라면 우측(right-tail) 유의확률을 사용한다. 우측 유의확률은 귀무가설이 맞음에도 불구하고 검정통계량이 현재 검정통계량과 같거나 더 큰 값이 나올 수 있는 확률이다.

$$
P( t \geq t_0 | H_0 )
$$

누적분포함수를 사용하면 다음 식으로 구할 수 있다. 

$$
  1 - F(t_0)
$$

만약 이산확률분포라면 등호가 성립하는 부분을 제외해야 하므로 다음처럼 구한다.

$$
1 - F(t_0 - 1)
$$

반대로 $$\theta$$가 음수이라는 것을 검정하고 싶다면 귀무가설과 대립가설은 다음과 같다.

$$
H_0: \theta = \theta_0, \;\;\; H_a: \theta < \theta_0
$$

만약 모수 $$\theta$$가 음수일 때 검정통계량도 작은 값이 나오기 쉬운 경우라면 좌측(left-tail) 유의확률을 사용한다. 좌측 유의확률은 귀무가설이 맞음에도 불구하고 실제로 나온 검정통계량과 같거나 더 작은 값이 나올 수 있는 확률이다.

$$
P( t \leq t_0 | H_0 )
$$

누적분포함수를 사용하면 다음 식으로 구할 수 있다.

$$
F(t_0)
$$

### 유의수준과 기각역

**유의확률의 값이 아주 작으면 귀무가설을 기각하고 대립가설을 채택할 수 있다.**

**유의수준(level of significance)**은 계산된 유의확률 값에 대해 귀무가설을 기각하는지 채택하는지를 결정할 수 있는 기준값 이다. 일반적으로 1%, 5%, 10% 등이다. 

**기각역(critical value)** 은 유의수준에 대해 계산된 검정통계량 이다.

### 검정 방법론

1. 데이터가 어떤 고정된 확률분포를 가지는 확률변수라고 가정한다. 예를 들어 동전은 베르누이 분포를 따르는 확률변수의 표본이며 트레이더의 수익률은 정규 분포를 따르는 확률변수의 표본이라고 가정한다.
2. 이 확률분포의 모수값이 특정한 값을 가진다고 가정한다. 이 때 모수가 가지는 특정한 값은 우리가 검증하고자 하는 사실과 관련이 있어야 한다. 이러한 가정을 **귀무가설(null hypothesis)**이라고 한다. 예를 들어 동전이 공정한 동전이라고 주장하는 것은 베르누이 확률분포의 모수 $$\theta$$의 값이 0.5 이라고 가정하는 것과 같다. 트레이더가 돈을 잃지 않는 다는 것은 정규 분포의 기댓값 모수 $$\mu$$ 가 0과 같거나, 그보다 크다고 가정하는 것이다.
3. 만약 데이터가 주어진 귀무가설에 따른 표본이고 이 표본 데이터를 특정한 수식에 따라 계산한 숫자는 특정한 확률분포를 따르게 된다. 이 숫자를 **검정통계량(test statistics)**라고 하며 검정통계량의 확률분포를 **검정 통계 분포(test statistics distribution)**라고 한다. 검정 통계 분포의 종류 및 모수의 값은 처음에 정한 가설 및 수식에 의해 결정된다.
4. 주어진 귀무가설이 맞으면서도 표본 데이터에 의해서 실제로 계산된 검정통계량의 값과 같은 혹은 그보다 더 극단적인(extreme) 또는 더 희귀한(rare) 값이 나올 수 있는 확률을 계산한다. 이를 **유의확률(p-value)**이라고 한다.
5. 만약 유의확률이 미리 정한 특정한 기준값보다 작은 경우를 생각하자. 이 기준값을 **유의수준(significance level)**이라고 하는 데 보통 1% 혹은 5% 정도의 작은 값을 지정한다. 유의확률이 유의수준으로 정한 값(예 1%)보다도 작다는 말은 해당 검정 통계 분포에서 이 검정 통계치(혹은 더 극단적인 경우)가 나올 수 있는 확률이 아주 작다는 의미이므로 가장 근본이 되는 가설 즉, 귀무가설이 틀렸다는 의미이다. 따라서 이 경우에는 귀무가설을 **기각(reject)**한다.
6. 만약 유의확률이 유의수준보다 크다면 해당 검정 통계 분포에서 이 검정 통계치가 나오는 것이 불가능하지만은 않다는 의미이므로 귀무가설을 기각할 수 없다. 따라서 이 경우에는 귀무가설을 **채택(accept)**한다.

