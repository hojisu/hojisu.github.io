
<!DOCTYPE HTML>
<html lang="" >
    <head>
        <meta charset="UTF-8">
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <title>그레디언트 최적화 알고리즘 요약 · GitBook</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="GitBook 3.2.3">
        
        
        
    
    <link rel="stylesheet" href="../../gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="../../gitbook/gitbook-plugin-etoc/plugin.css">
                
            
                
                <link rel="stylesheet" href="../../gitbook/gitbook-plugin-splitter/splitter.css">
                
            
                
                <link rel="stylesheet" href="../../gitbook/gitbook-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="../../gitbook/gitbook-plugin-search/search.css">
                
            
                
                <link rel="stylesheet" href="../../gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
    
        
    
        
    
        
    
        
    
        
    

        
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../../gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="../../gitbook/images/favicon.ico" type="image/x-icon">

    
    <link rel="next" href="cnn/" />
    
    
    <link rel="prev" href="04neuralnetwork-optimization.html" />
    

    </head>
    <body>
        
<div class="book">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="Type to search" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    

    

    
        
        
    
        <li class="chapter " data-level="1.1" data-path="../../">
            
                <a href="../../">
            
                    
                    Introduction
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2" data-path="../math/">
            
                <a href="../math/">
            
                    
                    수학
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.1" data-path="../math/linearalgebra/">
            
                <a href="../math/linearalgebra/">
            
                    
                    선형대수
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.1.1" data-path="../math/linearalgebra/0201data-and-matrix.html">
            
                <a href="../math/linearalgebra/0201data-and-matrix.html">
            
                    
                    데이터와 행렬
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.1.2" data-path="../math/linearalgebra/0202vector-and-matrix-calculation.html">
            
                <a href="../math/linearalgebra/0202vector-and-matrix-calculation.html">
            
                    
                    벡터와 행렬의 연산
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.1.3" data-path="../math/linearalgebra/0203matrix-character.html">
            
                <a href="../math/linearalgebra/0203matrix-character.html">
            
                    
                    행렬의 성질
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.1.4" data-path="../math/linearalgebra/0204system-of-linear-equations.html">
            
                <a href="../math/linearalgebra/0204system-of-linear-equations.html">
            
                    
                    선형연립방정식과 역행렬
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.1.5" data-path="../math/linearalgebra/0301linear-algebra.html">
            
                <a href="../math/linearalgebra/0301linear-algebra.html">
            
                    
                    선형대수와 해석기하의 기초
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.1.6" data-path="../math/linearalgebra/0302coordinate-transform.html">
            
                <a href="../math/linearalgebra/0302coordinate-transform.html">
            
                    
                    좌표변환
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.1.7" data-path="../math/linearalgebra/0303eigenvalue-decomposition.html">
            
                <a href="../math/linearalgebra/0303eigenvalue-decomposition.html">
            
                    
                    고윳값 분해
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.1.8" data-path="../math/linearalgebra/0304svd.html">
            
                <a href="../math/linearalgebra/0304svd.html">
            
                    
                    특이값 분해
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.1.9" data-path="../math/linearalgebra/0305pca.html">
            
                <a href="../math/linearalgebra/0305pca.html">
            
                    
                    PCA
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.2.2" data-path="../math/calculus/">
            
                <a href="../math/calculus/">
            
                    
                    미적분
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.2.1" data-path="../math/calculus/0401function.html">
            
                <a href="../math/calculus/0401function.html">
            
                    
                    함수
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.2.2" data-path="../math/calculus/0402function-differentiation.html">
            
                <a href="../math/calculus/0402function-differentiation.html">
            
                    
                    함수 미분
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.2.3" data-path="../math/calculus/0403integral.html">
            
                <a href="../math/calculus/0403integral.html">
            
                    
                    적분
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.2.4" data-path="../math/calculus/0404matrix-differentiation.html">
            
                <a href="../math/calculus/0404matrix-differentiation.html">
            
                    
                    행렬의 미분
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.2.3" data-path="../math/optimization/">
            
                <a href="../math/optimization/">
            
                    
                    최적화
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.3.1" data-path="../math/optimization/0501optimization.html">
            
                <a href="../math/optimization/0501optimization.html">
            
                    
                    최적화 기초
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.3.2" data-path="../math/optimization/0502constrained-optimization.html">
            
                <a href="../math/optimization/0502constrained-optimization.html">
            
                    
                    제한조건이 있는 최적화 문제
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.3.3" data-path="../math/optimization/0503lp-qp-problem.html">
            
                <a href="../math/optimization/0503lp-qp-problem.html">
            
                    
                    LP문제 & QP문제
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.2.4" data-path="../math/probability-statistics/">
            
                <a href="../math/probability-statistics/">
            
                    
                    확률과 통계
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.4.1" data-path="../math/probability-statistics/0602probability.html">
            
                <a href="../math/probability-statistics/0602probability.html">
            
                    
                    확률의 수학적 정의와 의미
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.4.2" data-path="../math/probability-statistics/0603probability-character.html">
            
                <a href="../math/probability-statistics/0603probability-character.html">
            
                    
                    확률의 성질
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.4.3" data-path="../math/probability-statistics/0604probability-distribution-function.html">
            
                <a href="../math/probability-statistics/0604probability-distribution-function.html">
            
                    
                    확률분포함수
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.4.4" data-path="../math/probability-statistics/0605joint-conditional-probability.html">
            
                <a href="../math/probability-statistics/0605joint-conditional-probability.html">
            
                    
                    결합확률과 조건부확률
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.4.5" data-path="../math/probability-statistics/0606baysian-rule.html">
            
                <a href="../math/probability-statistics/0606baysian-rule.html">
            
                    
                    베이즈 정리
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.4.6" data-path="../math/probability-statistics/0701probabilistic-data-descriptive.html">
            
                <a href="../math/probability-statistics/0701probabilistic-data-descriptive.html">
            
                    
                    확률적데이터와 확률변수
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.4.7" data-path="../math/probability-statistics/0702expectation.html">
            
                <a href="../math/probability-statistics/0702expectation.html">
            
                    
                    기댓값
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.4.8" data-path="../math/probability-statistics/0703variance.html">
            
                <a href="../math/probability-statistics/0703variance.html">
            
                    
                    분산 & 표준편차
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.4.9" data-path="../math/probability-statistics/0704multivariate-probability-variable.html">
            
                <a href="../math/probability-statistics/0704multivariate-probability-variable.html">
            
                    
                    다변수 확률변수
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.4.10" data-path="../math/probability-statistics/0705covariance-correlation.html">
            
                <a href="../math/probability-statistics/0705covariance-correlation.html">
            
                    
                    공분산과 상관계수
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.4.11" data-path="../math/probability-statistics/0706conditional-expectation.html">
            
                <a href="../math/probability-statistics/0706conditional-expectation.html">
            
                    
                    조건부 기댓값
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.4.12" data-path="../math/probability-statistics/0801scipy-distribution.html">
            
                <a href="../math/probability-statistics/0801scipy-distribution.html">
            
                    
                    Scipy를 이용한 확률분포 분석
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.4.13" data-path="../math/probability-statistics/0802bernoulli-binomial-distribution.html">
            
                <a href="../math/probability-statistics/0802bernoulli-binomial-distribution.html">
            
                    
                    베르누이분포 & 이항분포
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.4.14" data-path="../math/probability-statistics/0803categorical-multinomial-distribution.html">
            
                <a href="../math/probability-statistics/0803categorical-multinomial-distribution.html">
            
                    
                    카테고리분포 & 다항분포
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.4.15" data-path="../math/probability-statistics/0804normal-distribution.html">
            
                <a href="../math/probability-statistics/0804normal-distribution.html">
            
                    
                    정규분포
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.4.16" data-path="../math/probability-statistics/0805t-chi-f-distribution.html">
            
                <a href="../math/probability-statistics/0805t-chi-f-distribution.html">
            
                    
                    스튜던트 t분포 & 카이분포 & F분포
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.4.17" data-path="../math/probability-statistics/0806mvn.html">
            
                <a href="../math/probability-statistics/0806mvn.html">
            
                    
                    다변수 가우시안 정규분포
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.4.18" data-path="../math/probability-statistics/0807beta-gamma-dirichlet.html">
            
                <a href="../math/probability-statistics/0807beta-gamma-dirichlet.html">
            
                    
                    베타분포 & 감마분포 & 디리클레분포
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.4.19" data-path="../math/probability-statistics/0901parameter-estimation.html">
            
                <a href="../math/probability-statistics/0901parameter-estimation.html">
            
                    
                    모수 추정
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.4.20" data-path="../math/probability-statistics/0902mle.html">
            
                <a href="../math/probability-statistics/0902mle.html">
            
                    
                    최대가능도와 모수추정
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.4.21" data-path="../math/probability-statistics/0903baysian-estimation.html">
            
                <a href="../math/probability-statistics/0903baysian-estimation.html">
            
                    
                    베이지안 모수추정
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.4.22" data-path="../math/probability-statistics/0904test-pvalue.html">
            
                <a href="../math/probability-statistics/0904test-pvalue.html">
            
                    
                    검정과 유의확률
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.4.23" data-path="../math/probability-statistics/0905scipy-estimation.html">
            
                <a href="../math/probability-statistics/0905scipy-estimation.html">
            
                    
                    Scipy를 사용한 검정
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.4.24" data-path="../math/probability-statistics/0906confidence-interval.html">
            
                <a href="../math/probability-statistics/0906confidence-interval.html">
            
                    
                    신뢰구간 추정
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.3" data-path="../regression/">
            
                <a href="../regression/">
            
                    
                    회귀분석
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.3.1" data-path="../regression/0101dataintro.html">
            
                <a href="../regression/0101dataintro.html">
            
                    
                    데이터분석 기초
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2" data-path="../regression/0102python-package-data.html">
            
                <a href="../regression/0102python-package-data.html">
            
                    
                    데이터와 파이썬 패키지
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.3" data-path="../regression/0201linear-regression.html">
            
                <a href="../regression/0201linear-regression.html">
            
                    
                    선형 회귀분석
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.4" data-path="../regression/0202regression-geometry.html">
            
                <a href="../regression/0202regression-geometry.html">
            
                    
                    회귀분석의 기하학
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.5" data-path="../regression/0203partial-regression.html">
            
                <a href="../regression/0203partial-regression.html">
            
                    
                    부분 회귀
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.6" data-path="../regression/0301missingdata.html">
            
                <a href="../regression/0301missingdata.html">
            
                    
                    누락데이터 처리
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.7" data-path="../regression/0304scale.html">
            
                <a href="../regression/0304scale.html">
            
                    
                    스케일링 & 조건수
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.8" data-path="../regression/0305dummy-variable.html">
            
                <a href="../regression/0305dummy-variable.html">
            
                    
                    풀랭크 & 축소랭크 방식
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.9" data-path="../regression/0401probability-linear-regression.html">
            
                <a href="../regression/0401probability-linear-regression.html">
            
                    
                    확률론적 선형회귀 모형
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.10" data-path="../regression/0402laverage-outlier.html">
            
                <a href="../regression/0402laverage-outlier.html">
            
                    
                    레버리지와 아웃라이어
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.11" data-path="../regression/0403anova.html">
            
                <a href="../regression/0403anova.html">
            
                    
                    분산분석
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.12" data-path="../regression/0404crossvalidation.html">
            
                <a href="../regression/0404crossvalidation.html">
            
                    
                    교차검증
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.13" data-path="../regression/0404regression-diagnosis.html">
            
                <a href="../regression/0404regression-diagnosis.html">
            
                    
                    회귀분석 모형의 진단
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.14" data-path="../regression/0501non-linear-model-trans.html">
            
                <a href="../regression/0501non-linear-model-trans.html">
            
                    
                    비선형모형 변형방법
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.15" data-path="../regression/0502basis-function-overfit.html">
            
                <a href="../regression/0502basis-function-overfit.html">
            
                    
                    기저함수모형과 과최적화
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.16" data-path="../regression/0503multicollinearity.html">
            
                <a href="../regression/0503multicollinearity.html">
            
                    
                    다중공선성
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.17" data-path="../regression/0504regularize.html">
            
                <a href="../regression/0504regularize.html">
            
                    
                    정규화
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.4" data-path="../timeseries/">
            
                <a href="../timeseries/">
            
                    
                    시계열 분석
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.4.1" data-path="../timeseries/0601timeseries-stochastic-process.html">
            
                <a href="../timeseries/0601timeseries-stochastic-process.html">
            
                    
                    시계열 자료와 확률과정
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.2" data-path="../timeseries/0602stationary-process.html">
            
                <a href="../timeseries/0602stationary-process.html">
            
                    
                    정상확률과정 & 에르고딕성질
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.3" data-path="../timeseries/0603whitenoise-randomwork.html">
            
                <a href="../timeseries/0603whitenoise-randomwork.html">
            
                    
                    백색잡음 & 랜덤워크
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.4" data-path="../timeseries/0604trend-season.html">
            
                <a href="../timeseries/0604trend-season.html">
            
                    
                    추세 & 계절성
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.5" data-path="../timeseries/0701general-linear-process.html">
            
                <a href="../timeseries/0701general-linear-process.html">
            
                    
                    일반선형확률과정 모형
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.5" data-path="../machine-learning/">
            
                <a href="../machine-learning/">
            
                    
                    머신러닝
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.5.1" data-path="../machine-learning/machine-learning-supervised/">
            
                <a href="../machine-learning/machine-learning-supervised/">
            
                    
                    머신러닝-지도학습
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.5.1.1" data-path="../machine-learning/machine-learning-supervised/0503classification-model.html">
            
                <a href="../machine-learning/machine-learning-supervised/0503classification-model.html">
            
                    
                    분류 모형의 종류
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.1.2" data-path="../machine-learning/machine-learning-supervised/0504classification-estimation.html">
            
                <a href="../machine-learning/machine-learning-supervised/0504classification-estimation.html">
            
                    
                    분류 성능평가
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.1.3" data-path="../machine-learning/machine-learning-supervised/0601logistickregression.html">
            
                <a href="../machine-learning/machine-learning-supervised/0601logistickregression.html">
            
                    
                    로지스틱 회귀분석
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.1.4" data-path="../machine-learning/machine-learning-supervised/0701lda-qda.html">
            
                <a href="../machine-learning/machine-learning-supervised/0701lda-qda.html">
            
                    
                    LDA & QDA
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.1.5" data-path="../machine-learning/machine-learning-supervised/0702naive.html">
            
                <a href="../machine-learning/machine-learning-supervised/0702naive.html">
            
                    
                    나이브베이즈 분류모형
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.1.6" data-path="../machine-learning/machine-learning-supervised/0801decisiontree.html">
            
                <a href="../machine-learning/machine-learning-supervised/0801decisiontree.html">
            
                    
                    의사결정나무
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.1.7" data-path="../machine-learning/machine-learning-supervised/0901ensemble.html">
            
                <a href="../machine-learning/machine-learning-supervised/0901ensemble.html">
            
                    
                    앙상블모형
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.1.8" data-path="../machine-learning/machine-learning-supervised/1001perceptron.html">
            
                <a href="../machine-learning/machine-learning-supervised/1001perceptron.html">
            
                    
                    퍼셉트론
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.1.9" data-path="../machine-learning/machine-learning-supervised/1002svm.html">
            
                <a href="../machine-learning/machine-learning-supervised/1002svm.html">
            
                    
                    서포트벡터 머신
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.1.10" data-path="../machine-learning/machine-learning-supervised/1101kernelsvm.html">
            
                <a href="../machine-learning/machine-learning-supervised/1101kernelsvm.html">
            
                    
                    커널 서포트벡터 머신
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.1.11" data-path="../machine-learning/machine-learning-supervised/1201modeloptimization.html">
            
                <a href="../machine-learning/machine-learning-supervised/1201modeloptimization.html">
            
                    
                    모형 최적화 방법
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.1.12" data-path="../machine-learning/machine-learning-supervised/1202imbalanceproblem.html">
            
                <a href="../machine-learning/machine-learning-supervised/1202imbalanceproblem.html">
            
                    
                    비대칭 데이터 문제
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.1.13" data-path="../machine-learning/machine-learning-supervised/1203featureselection.html">
            
                <a href="../machine-learning/machine-learning-supervised/1203featureselection.html">
            
                    
                    특징변수 선택
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.1.14" data-path="../machine-learning/machine-learning-supervised/discriminative-generative.html">
            
                <a href="../machine-learning/machine-learning-supervised/discriminative-generative.html">
            
                    
                    결정론적 모형 & 생성모형
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.1.15" data-path="../machine-learning/machine-learning-supervised/machine-learning.html">
            
                <a href="../machine-learning/machine-learning-supervised/machine-learning.html">
            
                    
                    기계학습 & 인공신경망 요약
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.5.2" data-path="../machine-learning/machine-learning-unsupervised/">
            
                <a href="../machine-learning/machine-learning-unsupervised/">
            
                    
                    머신러닝-비지도학습
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.5.2.1" data-path="../machine-learning/machine-learning-unsupervised/1401clustering.html">
            
                <a href="../machine-learning/machine-learning-unsupervised/1401clustering.html">
            
                    
                    군집화
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.2.2" data-path="../machine-learning/machine-learning-unsupervised/1402kmeans.html">
            
                <a href="../machine-learning/machine-learning-unsupervised/1402kmeans.html">
            
                    
                    K-Means
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.2.3" data-path="../machine-learning/machine-learning-unsupervised/1403dbscan.html">
            
                <a href="../machine-learning/machine-learning-unsupervised/1403dbscan.html">
            
                    
                    DBSCANE
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.2.4" data-path="../machine-learning/machine-learning-unsupervised/1404hierachical-clustering.html">
            
                <a href="../machine-learning/machine-learning-unsupervised/1404hierachical-clustering.html">
            
                    
                    계층적 군집화
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.2.5" data-path="../machine-learning/machine-learning-unsupervised/1405affinity-propagation.html">
            
                <a href="../machine-learning/machine-learning-unsupervised/1405affinity-propagation.html">
            
                    
                    Affinity Propagation
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.2.6" data-path="../machine-learning/machine-learning-unsupervised/knn.html">
            
                <a href="../machine-learning/machine-learning-unsupervised/knn.html">
            
                    
                    KNN
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.5.2.6.1" data-path="../machine-learning/machine-learning-unsupervised/1801gmm.html">
            
                <a href="../machine-learning/machine-learning-unsupervised/1801gmm.html">
            
                    
                    가우시안 혼합 모형과 EM방법
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.5.3" data-path="../machine-learning/probability-graph-model/">
            
                <a href="../machine-learning/probability-graph-model/">
            
                    
                    그래프 확률 모형
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.5.3.1" data-path="../machine-learning/probability-graph-model/1501graph.html">
            
                <a href="../machine-learning/probability-graph-model/1501graph.html">
            
                    
                    그래프 기초
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.2" data-path="../machine-learning/probability-graph-model/1502graphical-probability-model.html">
            
                <a href="../machine-learning/probability-graph-model/1502graphical-probability-model.html">
            
                    
                    그래프 확률 모형
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.3" data-path="../machine-learning/probability-graph-model/1503network.html">
            
                <a href="../machine-learning/probability-graph-model/1503network.html">
            
                    
                    네트워크 추론
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.4" data-path="../machine-learning/probability-graph-model/1504hiddenmarkov.html">
            
                <a href="../machine-learning/probability-graph-model/1504hiddenmarkov.html">
            
                    
                    히든마코프 모형
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.5.4" data-path="../machine-learning/recommendsystem/">
            
                <a href="../machine-learning/recommendsystem/">
            
                    
                    추천시스템
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.5.4.1" data-path="../machine-learning/recommendsystem/recommend.html">
            
                <a href="../machine-learning/recommendsystem/recommend.html">
            
                    
                    추천시스템
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.4.2" data-path="../machine-learning/recommendsystem/fm.html">
            
                <a href="../machine-learning/recommendsystem/fm.html">
            
                    
                    Factorization Machine
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.5.5" data-path="../machine-learning/machine-learning-advanced/">
            
                <a href="../machine-learning/machine-learning-advanced/">
            
                    
                    머신러닝 심화편
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.5.5.1" data-path="../machine-learning/machine-learning-advanced/1802calculus-of-variations.html">
            
                <a href="../machine-learning/machine-learning-advanced/1802calculus-of-variations.html">
            
                    
                    변분법 추론
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.5.2" data-path="../machine-learning/machine-learning-advanced/1701montecalro.html">
            
                <a href="../machine-learning/machine-learning-advanced/1701montecalro.html">
            
                    
                    몬테카를로 베이지안 분석
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.6" data-path="./">
            
                <a href="./">
            
                    
                    딥러닝
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.6.1" data-path="01neuralnetwork.html">
            
                <a href="01neuralnetwork.html">
            
                    
                    신경망
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2" data-path="02gradient-vanishing.html">
            
                <a href="02gradient-vanishing.html">
            
                    
                    그레디언트 소멸 문제
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.3" data-path="03neuralnetwork-performance.html">
            
                <a href="03neuralnetwork-performance.html">
            
                    
                    신경망 성능 개선 방법
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.4" data-path="04neuralnetwork-optimization.html">
            
                <a href="04neuralnetwork-optimization.html">
            
                    
                    신경망 최적화 방법
            
                </a>
            

            
        </li>
    
        <li class="chapter active" data-level="1.6.5" data-path="gd-algorithem.html">
            
                <a href="gd-algorithem.html">
            
                    
                    그레디언트 최적화 알고리즘 요약
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.6" data-path="cnn/">
            
                <a href="cnn/">
            
                    
                    CNN
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.6.6.1" data-path="cnn/00cnn.html">
            
                <a href="cnn/00cnn.html">
            
                    
                    CNN
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.6.2" data-path="cnn/01alexnet.html">
            
                <a href="cnn/01alexnet.html">
            
                    
                    AlexNet
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.6.3" data-path="cnn/02googlenet.html">
            
                <a href="cnn/02googlenet.html">
            
                    
                    GooLeNet
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.6.4" data-path="cnn/03resnet.html">
            
                <a href="cnn/03resnet.html">
            
                    
                    ResNet
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.6.5" data-path="cnn/04densenet.html">
            
                <a href="cnn/04densenet.html">
            
                    
                    DanseNet
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.6.7" data-path="rnn/">
            
                <a href="rnn/">
            
                    
                    RNN
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.6.7.1" data-path="rnn/lstm.html">
            
                <a href="rnn/lstm.html">
            
                    
                    LSTM
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.7.2" data-path="rnn/rnn.html">
            
                <a href="rnn/rnn.html">
            
                    
                    RNN
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.6.8" data-path="autoencoder.html">
            
                <a href="autoencoder.html">
            
                    
                    AutoEncoder
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.9" data-path="gan.html">
            
                <a href="gan.html">
            
                    
                    GAN
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.10" data-path="vae.html">
            
                <a href="vae.html">
            
                    
                    VAE
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.7" data-path="../natural-language/">
            
                <a href="../natural-language/">
            
                    
                    자연어 처리
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.7.1" data-path="../natural-language/scikit-learn-text-preprocess.html">
            
                <a href="../natural-language/scikit-learn-text-preprocess.html">
            
                    
                    Scikit-Learn의 텍스트 전처리
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.2" data-path="../natural-language/probabilistic-language.html">
            
                <a href="../natural-language/probabilistic-language.html">
            
                    
                    확률론적 언어 모형
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.3" data-path="../natural-language/wordembedding.html">
            
                <a href="../natural-language/wordembedding.html">
            
                    
                    단어 임베딩
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
            Published with GitBook
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href="../.." >그레디언트 최적화 알고리즘 요약</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <h1 id="gradient-descent-optimization-algorithms">Gradient Descent Optimization Algorithms</h1>
<!-- toc --><div id="toc" class="toc">

<ul>
<li><a href="#summary">Summary</a></li>
<li><a href="#gradient-desent--stochastic-gradient-descent">Gradient Desent &amp; Stochastic Gradient Descent</a></li>
<li><a href="#sgd&#xC758;-&#xBCC0;&#xD615;-&#xC54C;&#xACE0;&#xB9AC;&#xC998;">SGD&#xC758; &#xBCC0;&#xD615; &#xC54C;&#xACE0;&#xB9AC;&#xC998;</a><ul>
<li><a href="#momentum">Momentum</a></li>
<li><a href="#adagradadaptive-gradient">Adagrad(Adaptive Gradient)</a></li>
<li><a href="#rmsprop">RMSProp</a></li>
<li><a href="#adam-adaptive-moment-estimation">Adam (Adaptive Moment Estimation)</a></li>
<li><a href="#etc">etc</a></li>
</ul>
</li>
</ul>

</div><!-- tocstop -->
<h3 id="summary">Summary</h3>
<ul>
<li>Gradient Descnet&#xBC29;&#xBC95;&#xC740; <script type="math/tex; ">\theta</script> (&#xC2E0;&#xACBD;&#xB9DD;&#xC758; parameter&#xB4E4;)&#xC5D0; &#xB300;&#xD574; gradient&#xC758; &#xBC18;&#xB300;&#xBC29;&#xD5A5;&#xC73C;&#xB85C; &#xC77C;&#xC815;&#xD06C;&#xAE30;&#xB9CC;&#xD07C; &#xC774;&#xB3D9;&#xD574;&#xB0B4;&#xB294; &#xAC83;&#xC744; &#xBC18;&#xBCF5;&#xD558;&#xC5EC; &#xC624;&#xCC28;&#xD568;&#xC218;&#xC758; &#xAC12;&#xC744; &#xCD5C;&#xC18C;&#xD654;&#xD558;&#xB294; <script type="math/tex; ">\theta</script> &#xAC12;&#xC744; &#xCC3E;&#xB294;&#xAC83;&#xC774;&#xB2E4;. </li>
<li>Full Batch Gradient Descent &#xD55C;&#xBC88; step&#xC744; &#xB0B4;&#xB51B;&#xC744; &#xB54C; &#xC804;&#xCCB4; &#xB370;&#xC774;&#xD130;&#xC5D0; &#xB300;&#xD574; &#xACC4;&#xC0B0;&#xD558;&#xB294; &#xAC83;&#xC73C;&#xB85C; &#xB108;&#xBB34; &#xB9CE;&#xC740; &#xACC4;&#xC0B0;&#xB7C9;&#xC774; &#xD544;&#xC694;&#xD558;&#xB2E4;. </li>
<li>Stocahstic Gradient Descent(SGD)&#xB294; &#xC77C;&#xBD80; &#xC870;&#xADF8;&#xB9CC;&#xD55C; &#xB370;&#xC774;&#xD130;&#xC758; &#xBAA8;&#xC74C;(mini-batch)&#xC5D0; &#xB300;&#xD574;&#xC11C;&#xB9CC; &#xACC4;&#xC0B0;&#xD55C;&#xB2E4;. full batch gradient descent&#xBCF4;&#xB2E4; &#xB2E4;&#xC18C; &#xBD80;&#xC815;&#xD655;&#xD560; &#xC218; &#xC788;&#xC9C0;&#xB9CC; &#xACC4;&#xC0B0; &#xC18D;&#xB3C4;&#xAC00; &#xD6E8;&#xC2E0; &#xBE60;&#xB974;&#xB2E4;. &#xC5EC;&#xB7EC;&#xBC88; &#xBC18;&#xBCF5;&#xD560; &#xACBD;&#xC6B0; &#xBCF4;&#xD1B5; batch&#xC758; &#xACB0;&#xACFC;&#xC640; &#xC720;&#xC0AC;&#xD55C; &#xACB0;&#xACFC;&#xB85C; &#xC218;&#xB834;&#xD55C;&#xB2E4;. &#xB610;&#xD55C; local minima&#xC5D0; &#xBE60;&#xC9C0;&#xC9C0; &#xC54A;&#xACE0; &#xB354; &#xC88B;&#xC740; &#xBC29;&#xD5A5;&#xC73C;&#xB85C; &#xC218;&#xB834;&#xD560; &#xAC00;&#xB2A5;&#xC131;&#xC774; &#xC788;&#xB2E4;.</li>
<li>Momentum &#xBC29;&#xC2DD;&#xC740; &#xD604;&#xC7AC; Gradient&#xB97C; &#xD1B5;&#xD574; &#xC774;&#xB3D9;&#xD558;&#xB294; &#xBC29;&#xD5A5;&#xACFC;&#xB294; &#xBCC4;&#xAC1C;&#xB85C; &#xACFC;&#xAC70;&#xC5D0; &#xC774;&#xB3D9;&#xD588;&#xB358; &#xBC29;&#xC2DD;&#xC744; &#xAE30;&#xC5B5;&#xD558;&#xBA74;&#xC11C; &#xADF8; &#xBC29;&#xD5A5;&#xC73C;&#xB85C; &#xC77C;&#xC815; &#xC815;&#xB3C4; &#xCD94;&#xAC00;&#xC801;&#xC73C;&#xB85C; &#xC774;&#xB3D9;&#xD558;&#xB294; &#xBC29;&#xC2DD;&#xC774;&#xB2E4;.</li>
<li>Adagrad&#xB294; &#xBCC0;&#xC218;&#xB4E4;&#xC744; update&#xD560; &#xB54C; &#xAC01;&#xAC01;&#xC758; &#xBCC0;&#xC218;&#xB9C8;&#xB2E4; step size&#xB97C; &#xB2E4;&#xB974;&#xAC8C; &#xC124;&#xC815;&#xD574;&#xC11C; &#xC774;&#xB3D9;&#xD558;&#xB294; &#xBC29;&#xC2DD;&#xC774;&#xB2E4;. &#xC774; &#xC54C;&#xACE0;&#xB9AC;&#xC998;&#xC758; &#xD575;&#xC2EC;&#xC740; &#xC9C0;&#xAE08;&#xAE4C;&#xC9C0; &#xB9CE;&#xC774; &#xBCC0;&#xD654;&#xD558;&#xC9C0; &#xC54A;&#xC740; &#xBCC0;&#xC218;&#xB4E4;&#xC740; step size&#xB97C; &#xD06C;&#xAC8C;&#xD558;&#xACE0;, &#xB9CE;&#xC774; &#xBCC0;&#xD654;&#xD588;&#xB358; &#xBCC0;&#xC218;&#xB4E4;&#xC740; step size&#xB97C; &#xC791;&#xAC8C; &#xD558;&#xB294; &#xAC83;&#xC774;&#xB2E4;. &#xC790;&#xC8FC; &#xB4F1;&#xC7A5;&#xD558;&#xAC70;&#xB098; &#xBCC0;&#xD654;&#xB97C; &#xB9CE;&#xC774; &#xD55C; &#xBCC0;&#xC218;&#xB4E4;&#xC758; &#xACBD;&#xC6B0; optimum&#xC5D0; &#xAC00;&#xAE4C;&#xC774; &#xC788;&#xC744; &#xD655;&#xB960;&#xC774; &#xB192;&#xAE30; &#xB54C;&#xBB38;&#xC5D0; &#xC791;&#xC740; &#xD06C;&#xAE30;&#xB85C; &#xC774;&#xB3D9;&#xD558;&#xBA74;&#xC11C; &#xC138;&#xBC00;&#xD55C; &#xAC12;&#xC744; &#xC870;&#xC815;&#xD558;&#xACE0;, &#xC801;&#xAC8C; &#xBCC0;&#xD654;&#xD55C; &#xBCC0;&#xC218;&#xB4E4;&#xC740; optimum &#xAC12;&#xC5D0; &#xB3C4;&#xB2EC;&#xD558;&#xAE30; &#xC704;&#xD574;&#xC11C;&#xB294; &#xB9CE;&#xC774; &#xC774;&#xB3D9;&#xD574;&#xC57C;&#xD560; &#xD655;&#xB960;&#xC774; &#xB192;&#xAE30; &#xB54C;&#xBB38;&#xC5D0; &#xBA3C;&#xC800; &#xBE60;&#xB974;&#xAC8C; loss &#xAC12;&#xC744; &#xC904;&#xC774;&#xB294; &#xBC29;&#xD5A5;&#xC73C;&#xB85C; &#xC774;&#xB3D9;&#xD558;&#xB824;&#xB294; &#xBC29;&#xC2DD;&#xC774;&#xB77C;&#xACE0; &#xC0DD;&#xAC01;&#xD560; &#xC218; &#xC788;&#xB2E4;.</li>
<li>RMSProp&#xC740; Adagrad&#xC758; &#xB2E8;&#xC810;&#xC744; &#xD574;&#xACB0;&#xD558;&#xAE30; &#xC704;&#xD55C; &#xBC29;&#xBC95;&#xC774;&#xB2E4;. Adagrad&#xC758; &#xC2DD;&#xC5D0;&#xC11C; gradient&#xC758; &#xC81C;&#xACF1;&#xAC12;&#xC744; &#xB354;&#xD574;&#xB098;&#xAC00;&#xBA74;&#xC11C; &#xAD6C;&#xD55C; <script type="math/tex; ">G_t</script> &#xBD80;&#xBD84;&#xC744; &#xD569;&#xC774;&#xC544;&#xB2C8;&#xB77C; &#xC9C0;&#xC218;&#xD3C9;&#xADE0;&#xC73C;&#xB85C; &#xBC14;&#xAFB8;&#xC5B4;&#xC11C; &#xB300;&#xCCB4;&#xD55C; &#xBC29;&#xBC95;&#xC774;&#xB2E4;. &#xC774;&#xB807;&#xAC8C; &#xB300;&#xCCB4;&#xB97C; &#xD560; &#xACBD;&#xC6B0; Adagrad&#xCC98;&#xB7FC; <script type="math/tex; ">G_t</script> &#xAC00; &#xBB34;&#xD55C;&#xC815; &#xCEE4;&#xC9C0;&#xC9C0; &#xC54A;&#xC73C;&#xBA74;&#xC11C; &#xCD5C;&#xADFC; &#xBCC0;&#xD654;&#xB7C9;&#xC758; &#xBCC0;&#xC218;&#xAC04; &#xC0C1;&#xB300;&#xC801;&#xC778; &#xD06C;&#xAE30; &#xCC28;&#xC774;&#xB294; &#xC720;&#xC9C0;&#xD560; &#xC218; &#xC788;&#xB2E4;. </li>
<li>Adam&#xC740; RMSProp&#xACFC; Mementum &#xBC29;&#xC2DD;&#xC744; &#xD569;&#xCE5C; &#xAC83; &#xAC19;&#xC740; &#xC54C;&#xACE0;&#xB9AC;&#xC998;&#xC774;&#xB2E4;. Momentum &#xBC29;&#xC2DD;&#xACFC; &#xC720;&#xC0AC;&#xD558;&#xAC8C; &#xC9C0;&#xAE08;&#xAE4C;&#xC9C0; &#xACC4;&#xC0B0;&#xD574;&#xC628; &#xAE30;&#xC6B8;&#xAE30;&#xC758; &#xC9C0;&#xC218;&#xD3C9;&#xADE0;&#xC744; &#xC800;&#xC7A5;&#xD558;&#xBA70; RMSProp&#xACFC; &#xC720;&#xC0AC;&#xD558;&#xAC8C; &#xAE30;&#xC6B8;&#xAE30;&#xC758; &#xC81C;&#xACF1;&#xAC12;&#xC758; &#xC9C0;&#xC218;&#xD3C9;&#xADE0;&#xC744; &#xC800;&#xC7A5;&#xD55C;&#xB2E4;. </li>
</ul>
<hr>
<h3 id="gradient-desent--stochastic-gradient-descent">Gradient Desent &amp; Stochastic Gradient Descent</h3>
<p>&#xC2E0;&#xACBD;&#xB9DD;&#xC758; &#xAC00;&#xC911;&#xCE58;&#xB97C; &#xC870;&#xC808;&#xD558;&#xB294; &#xACFC;&#xC815;&#xC5D0;&#xB294; &#xBCF4;&#xD1B5; Gradient Descent &#xBC29;&#xBC95;&#xC744; &#xC0AC;&#xC6A9;&#xD55C;&#xB2E4;. &#xC774; &#xBC29;&#xBC95;&#xC740; &#xC2E0;&#xACBD;&#xB9DD;&#xC758; parameter&#xB4E4;&#xC744; <script type="math/tex; ">\theta</script> &#xB77C;&#xACE0; &#xD588;&#xC744; &#xB54C; &#xC2E0;&#xACBD;&#xB9DD;&#xC5D0;&#xC11C; &#xB098;&#xC624;&#xB294; &#xACB0;&#xACFC;&#xAC12;&#xACFC; &#xC2E4;&#xC81C;&#xAC12; &#xC0AC;&#xC774;&#xC758; &#xCC28;&#xC774;&#xB97C; &#xC815;&#xC758;&#xD558;&#xB294; &#xD568;&#xC218; Loss function <script type="math/tex; ">J(\theta)</script> &#xC758; &#xAC12;&#xC744; &#xCD5C;&#xC18C;&#xD654;&#xD558;&#xAE30; &#xC704;&#xD574; &#xAE30;&#xC6B8;&#xAE30;(gradient) <script type="math/tex; ">\nabla_{\theta}J(\theta)</script> &#xB97C; &#xC774;&#xC6A9;&#xD558;&#xB294; &#xBC29;&#xBC95;&#xC774;&#xB2E4;. Gradient Descent&#xC5D0;&#xC11C;&#xB294; <script type="math/tex; ">\theta</script> &#xC5D0; &#xB300;&#xD574; gradient&#xC758; &#xBC18;&#xB300;&#xBC29;&#xD5A5;&#xC73C;&#xB85C; &#xC77C;&#xC815; &#xD06C;&#xAE30;&#xB9CC;&#xD07C; &#xC774;&#xB3D9;&#xD574;&#xB0B4;&#xB294; &#xAC83;&#xC744; &#xBC18;&#xBCF5;&#xD558;&#xC5EC; Loss function <script type="math/tex; ">J(\theta)</script> &#xC758; &#xAC12;&#xC744; &#xCD5C;&#xC18C;&#xD654; &#xD558;&#xB294; <script type="math/tex; ">\theta</script> &#xAC12;&#xC744; &#xCC3E;&#xB294; &#xAC83;&#xC774;&#xB2E4;. &#xD55C; &#xBC18;&#xBCF5;(iteration)&#xC5D0;&#xC11C;&#xC758; &#xBCC0;&#xD654;&#xC2DD;&#xC740; &#xB2E4;&#xC74C;&#xACFC; &#xAC19;&#xB2E4;. &#xC774; &#xB54C; <script type="math/tex; ">\eta</script> &#xB294; &#xBBF8;&#xB9AC; &#xC815;&#xD574;&#xC9C4; &#xAC78;&#xC74C;&#xC758; &#xD06C;&#xAE30; step size&#xB85C;&#xC11C; &#xBCF4;&#xD1B5; 0.01 ~ 0.001 &#xC815;&#xB3C4;&#xC758; &#xC801;&#xB2F9;&#xD55C; &#xD06C;&#xAE30;&#xB97C; &#xC0AC;&#xC6A9;&#xD55C;&#xB2E4;.</p>
<p><script type="math/tex; mode=display">
\theta = \theta - \eta \nabla_{\theta} J(\theta)
</script></p>
<p>Loss function&#xC744; &#xACC4;&#xC0B0;&#xD560; &#xB54C; &#xC804;&#xCCB4; train set&#xC744; &#xC0AC;&#xC6A9;&#xD558;&#xB294; &#xAC83;&#xC744; <strong>Full Batch Gradient Descent</strong> &#xB77C;&#xACE0; &#xD55C;&#xB2E4;. &#xD55C;&#xBC88; step&#xC744; &#xB0B4;&#xB51B;&#xC744; &#xB54C; &#xC804;&#xCCB4; &#xB370;&#xC774;&#xD130;&#xC5D0; &#xB300;&#xD574; Loss Function&#xC744; &#xACC4;&#xC0B0;&#xD574;&#xC57C;&#xD558;&#xBBC0;&#xB85C; &#xB108;&#xBB34; &#xB9CE;&#xC740; &#xACC4;&#xC0B0;&#xB7C9;&#xC774; &#xD544;&#xC694;&#xD558;&#xB2E4;. </p>
<p>&#xC774;&#xB97C; &#xBC29;&#xC9C0;&#xD558;&#xAE30; &#xC704;&#xD574; &#xBCF4;&#xD1B5;&#xC740; <strong>Stochastic Gradient Descent(SGD)</strong> &#xBC29;&#xBC95;&#xC744; &#xC0AC;&#xC6A9;&#xD55C;&#xB2E4;. loss function&#xC744; &#xACC4;&#xC0B0;&#xD55C; &#xB54C; &#xC77C;&#xBD80; &#xC870;&#xADF8;&#xB9CC;&#xD55C; &#xB370;&#xC774;&#xD130;&#xC758; &#xBAA8;&#xC74C;(mini-batch)&#xC5D0; &#xB300;&#xD574;&#xC11C;&#xB9CC; &#xACC4;&#xC0B0;&#xD55C;&#xB2E4;. full batch gradient descent&#xBCF4;&#xB2E4; &#xB2E4;&#xC18C; &#xBD80;&#xC815;&#xD655;&#xD560; &#xC218; &#xC788;&#xC9C0;&#xB9CC; &#xACC4;&#xC0B0; &#xC18D;&#xB3C4;&#xAC00; &#xD6E8;&#xC2E0; &#xBE60;&#xB974;&#xACE0; &#xAC19;&#xC740; &#xC2DC;&#xAC04;&#xC5D0; &#xB354; &#xB9CE;&#xC740; step&#xC744; &#xAC08; &#xC218; &#xC788;&#xC73C;&#xBA70; &#xC5EC;&#xB7EC;&#xBC88; &#xBC18;&#xBCF5;&#xD560; &#xACBD;&#xC6B0; &#xBCF4;&#xD1B5; batch&#xC758; &#xACB0;&#xACFC;&#xC640; &#xC720;&#xC0AC;&#xD55C; &#xACB0;&#xACFC;&#xB85C; &#xC218;&#xB834;&#xD55C;&#xB2E4;. &#xB610;&#xD55C; local minima&#xC5D0; &#xBE60;&#xC9C0;&#xC9C0; &#xC54A;&#xACE0; &#xB354; &#xC88B;&#xC740; &#xBC29;&#xD5A5;&#xC73C;&#xB85C; &#xC218;&#xB834;&#xD560; &#xAC00;&#xB2A5;&#xC131;&#xC774; &#xC788;&#xB2E4;. </p>
<h3 id="sgd&#xC758;-&#xBCC0;&#xD615;-&#xC54C;&#xACE0;&#xB9AC;&#xC998;">SGD&#xC758; &#xBCC0;&#xD615; &#xC54C;&#xACE0;&#xB9AC;&#xC998;</h3>
<h4 id="momentum">Momentum</h4>
<p>Momentum &#xBC29;&#xC2DD;&#xC744; Gradient Descent&#xB97C; &#xD1B5;&#xD574; &#xC774;&#xB3D9;&#xD558;&#xB294; &#xACFC;&#xC815;&#xC5D0; &#xC77C;&#xC885;&#xC758; &apos;&#xAD00;&#xC131;&apos;&#xC744; &#xC8FC;&#xB294; &#xAC83;&#xC774;&#xB2E4;. &#xD604;&#xC7AC; Gradient&#xB97C; &#xD1B5;&#xD574; &#xC774;&#xB3D9;&#xD558;&#xB294; &#xBC29;&#xD5A5;&#xACFC;&#xB294; &#xBCC4;&#xAC1C;&#xB85C; &#xACFC;&#xAC70;&#xC5D0; &#xC774;&#xB3D9;&#xD588;&#xB358; &#xBC29;&#xC2DD;&#xC744; &#xAE30;&#xC5B5;&#xD558;&#xBA74;&#xC11C; &#xADF8; &#xBC29;&#xD5A5;&#xC73C;&#xB85C; &#xC77C;&#xC815; &#xC815;&#xB3C4;&#xB97C; &#xCD94;&#xAC00;&#xC801;&#xC73C;&#xB85C; &#xC774;&#xB3D9;&#xD558;&#xB294; &#xBC29;&#xC2DD;&#xC774;&#xB2E4;. <script type="math/tex; ">v_t</script> &#xB97C; time step t&#xC5D0;&#xC11C;&#xC758; &#xC774;&#xB3D9;&#xBCA1;&#xD130;&#xB77C;&#xACE0; &#xD560; &#xB54C;, &#xB2E4;&#xC74C;&#xACFC; &#xAC19;&#xC740; &#xC2DD;&#xC73C;&#xB85C; &#xC774;&#xB3D9;&#xC744; &#xD45C;&#xD604;&#xD560; &#xC218; &#xC788;&#xB2E4;. </p>
<p><script type="math/tex; mode=display">
v_t = \gamma v_{t-1} + \eta \nabla_{\theta}J(\theta) \\
\theta = \theta - v_t
</script></p>
<p><script type="math/tex; ">\gamma</script> &#xB294; &#xC5BC;&#xB9C8;&#xB098; momentum&#xC744; &#xC904;&#xAC83;&#xC778;&#xC9C0;&#xC5D0; &#xB300;&#xD55C; momentum term(&#xAD00;&#xC131;&#xD56D;)&#xB85C;&#xC11C; &#xBCF4;&#xD1B5; 0.9&#xC815;&#xB3C4;&#xC758; &#xAC12;&#xC744; &#xC0AC;&#xC6A9;&#xD55C;&#xB2E4;. &#xC2DD;&#xC744; &#xBCF4;&#xBA74; &#xACFC;&#xAC70;&#xC5D0; &#xC5BC;&#xB9C8;&#xB098; &#xC774;&#xB3D9;&#xD588;&#xB294;&#xC9C0;&#xC5D0; &#xB300;&#xD55C; &#xC774;&#xB3D9;&#xD56D; v&#xB97C; &#xAE30;&#xC5B5;&#xD558;&#xACE0; &#xC0C8;&#xB85C;&#xC6B4; &#xC774;&#xB3D9;&#xD56D;&#xC744; &#xAD6C;&#xD560; &#xACBD;&#xC6B0; &#xACFC;&#xAC70;&#xC5D0; &#xC774;&#xB3D9;&#xD588;&#xB358; &#xC815;&#xB3C4;&#xC5D0; &#xAD00;&#xC131;&#xD56D;&#xB9CC;&#xD07C; &#xACF1;&#xD574;&#xC900; &#xD6C4; Gradient&#xC744; &#xC774;&#xC6A9;&#xD55C; step &#xD56D;&#xC744; &#xB354;&#xD574;&#xC900;&#xB2E4;. Gradient&#xB4E4;&#xC758; &#xC9C0;&#xC218;&#xD3C9;&#xADE0;&#xC744; &#xC774;&#xC6A9;&#xD558;&#xC5EC; &#xC774;&#xB3D9;&#xD55C;&#xB2E4;&#xACE0;&#xB3C4; &#xD574;&#xC11D;&#xD560; &#xC218; &#xC788;&#xB2E4;. </p>
<p><script type="math/tex; mode=display">
v_t = \eta \nabla_{\theta}J(\theta)_t + \gamma \eta \nabla_{\theta}J(\theta)_{t-1} +\gamma^2 \eta \nabla_{\theta}J(\theta)_{t-2} + ....
</script></p>
<p>momentum &#xBC29;&#xC2DD;&#xC740; SGD&#xAC00; oscilation(&#xC9C4;&#xB3D9;)&#xD604;&#xC0C1;&#xC744; &#xACAA;&#xC744; &#xB54C; &#xB354;&#xC6B1; &#xBE5B;&#xC744; &#xBC1C;&#xD55C;&#xB2E4;. </p>
<p>&#xB2E4;&#xC74C;&#xC740; SGD&#xAC00; &#xC9C4;&#xB3D9;&#xD604;&#xC0C1;&#xC744; &#xACAA;&#xACE0; &#xC788;&#xB294; &#xC0C1;&#xD669;&#xC774;&#xB2E4;. </p>
<p>SGD&#xB294; &#xC911;&#xC559;&#xC758; &#xCD5C;&#xC801;&#xC810;&#xC73C;&#xB85C; &#xC774;&#xB3D9;&#xD574;&#xC57C;&#xB418;&#xB294;&#xB370; &#xD55C;&#xBC88;&#xC758; step&#xC5D0;&#xC11C; &#xC6C0;&#xC9C1;&#xC77C; &#xC218; &#xC788;&#xB294; step size&#xB294; &#xD55C;&#xACC4;&#xAC00; &#xC788;&#xC73C;&#xBBC0;&#xB85C; &#xC774;&#xB7EC;&#xD55C; &#xC9C4;&#xB3D9;&#xD604;&#xC0C1;&#xC774; &#xC77C;&#xC5B4;&#xB0A0; &#xB54C; &#xC88C;&#xC6B0;&#xB85C; &#xACC4;&#xC18D; &#xC9C4;&#xB3D9;&#xD558;&#xBA74;&#xC11C; &#xC774;&#xB3D9;&#xC774; &#xB09C;&#xD56D;&#xC744; &#xACAA;&#xB294;&#xB2E4;.</p>
<p><img src="../../../resource/img/image-20200404220402100.png" alt="image-20200404220402100"></p>
<p>&#xB2E4;&#xC74C;&#xC740; Momentum &#xBC29;&#xC2DD;&#xC744; &#xC0AC;&#xC6A9;&#xD560; &#xACBD;&#xC6B0;&#xC774;&#xB2E4;.</p>
<p>Momentum &#xBC29;&#xC2DD;&#xC740; &#xC790;&#xC8FC; &#xC774;&#xB3D9;&#xD558;&#xB294; &#xBC29;&#xD5A5;&#xC5D0; &#xAD00;&#xC131;&#xC774; &#xAC78;&#xB9AC;&#xAC8C; &#xB418;&#xACE0; &#xC9C4;&#xB3D9;&#xC744; &#xD558;&#xB354;&#xB77C;&#xB3C4; &#xC911;&#xC559;&#xC73C;&#xB85C; &#xAC00;&#xB294; &#xBC29;&#xD5A5;&#xC5D0; &#xD798;&#xC744; &#xC5BB;&#xAE30; &#xB54C;&#xBB38;&#xC5D0; SGD&#xC5D0; &#xBE44;&#xD574; &#xC0C1;&#xB300;&#xC801;&#xC73C;&#xB85C; &#xBE60;&#xB974;&#xAC8C; &#xC774;&#xB3D9;&#xD560; &#xC218; &#xC788;&#xB2E4;. </p>
<p><img src="../../../resource/img/image-20200404220706454.png" alt="image-20200404220706454"></p>
<p>Momentum &#xBC29;&#xC2DD;&#xC740; &#xC544;&#xB798;&#xC758; &#xADF8;&#xB9BC;&#xACFC; &#xAC19;&#xC774; local minima&#xB97C; &#xBE60;&#xC838;&#xB098;&#xC624;&#xB294; &#xD6A8;&#xACFC;&#xAC00; &#xC788;&#xC744; &#xAC83;&#xC774;&#xB77C;&#xACE0; &#xAE30;&#xB300;&#xD560; &#xC218; &#xC788;&#xB2E4;. &#xAE30;&#xC874;&#xC758; SGD&#xB97C; &#xC774;&#xC6A9;&#xD560; &#xACBD;&#xC6B0; &#xC88C;&#xCE21;&#xC758; local minima&#xC5D0; &#xBE60;&#xC9C0;&#xBA74; gradient&#xAC00; 0&#xC774; &#xB418;&#xC5B4; &#xC774;&#xB3D9;&#xD560; &#xC218;&#xAC00; &#xC5C6;&#xC9C0;&#xB9CC; momentum &#xBC29;&#xC2DD;&#xC758; &#xACBD;&#xC6B0; &#xAE30;&#xC874;&#xC5D0; &#xC774;&#xB3D9;&#xD588;&#xB358; &#xBC29;&#xD5A5;&#xC5D0; &#xAD00;&#xC131;&#xC774; &#xC788;&#xC5B4; &#xC774; local minima&#xB97C; &#xBE60;&#xC838;&#xB098;&#xC624;&#xACE0; &#xB354; &#xC88B;&#xC740; minima&#xB85C; &#xC774;&#xB3D9;&#xD560; &#xAC83;&#xC744; &#xAE30;&#xB300;&#xD560; &#xC218; &#xC788;&#xB2E4;. &#xBC18;&#xBA74; momentum &#xBC29;&#xC2DD;&#xC744; &#xC774;&#xC6A9;&#xD560; &#xACBD;&#xC6B0; &#xAE30;&#xC874;&#xC758; &#xBCC0;&#xC218;&#xB4E4; <script type="math/tex; ">\theta</script> &#xC678;&#xC5D0;&#xB3C4; &#xACFC;&#xAC70;&#xC5D0; &#xC774;&#xB3D9;&#xD588;&#xB358; &#xC591;&#xC744; &#xBCC0;&#xC218;&#xB85C; &#xC800;&#xC7A5;&#xD574;&#xC57C;&#xD558;&#xAE30; &#xB54C;&#xBB38;&#xC5D0; &#xBCC0;&#xC218;&#xC5D0; &#xB300;&#xD55C; &#xBA54;&#xBAA8;&#xB9AC;&#xAC00; &#xAE30;&#xC874;&#xC758; &#xB450;&#xBC30;&#xAC00; &#xD544;&#xC694;&#xD558;&#xB2E4;. </p>
<p><img src="../../../resource/img/image-20200404221116469.png" alt="image-20200404221116469"></p>
<h4 id="adagradadaptive-gradient">Adagrad(Adaptive Gradient)</h4>
<p>Adagrad&#xB294; &#xBCC0;&#xC218;&#xB4E4;&#xC744; update&#xD560; &#xB54C; &#xAC01;&#xAC01;&#xC758; &#xBCC0;&#xC218;&#xB9C8;&#xB2E4; step size&#xB97C; &#xB2E4;&#xB974;&#xAC8C; &#xC124;&#xC815;&#xD574;&#xC11C; &#xC774;&#xB3D9;&#xD558;&#xB294; &#xBC29;&#xC2DD;&#xC774;&#xB2E4;. &#xC774; &#xC54C;&#xACE0;&#xB9AC;&#xC998;&#xC758; &#xD575;&#xC2EC;&#xC740; &#xC9C0;&#xAE08;&#xAE4C;&#xC9C0; &#xB9CE;&#xC774; &#xBCC0;&#xD654;&#xD558;&#xC9C0; &#xC54A;&#xC740; &#xBCC0;&#xC218;&#xB4E4;&#xC740; step size&#xB97C; &#xD06C;&#xAC8C;&#xD558;&#xACE0;, &#xB9CE;&#xC774; &#xBCC0;&#xD654;&#xD588;&#xB358; &#xBCC0;&#xC218;&#xB4E4;&#xC740; step size&#xB97C; &#xC791;&#xAC8C; &#xD558;&#xB294; &#xAC83;&#xC774;&#xB2E4;. &#xC790;&#xC8FC; &#xB4F1;&#xC7A5;&#xD558;&#xAC70;&#xB098; &#xBCC0;&#xD654;&#xB97C; &#xB9CE;&#xC774; &#xD55C; &#xBCC0;&#xC218;&#xB4E4;&#xC758; &#xACBD;&#xC6B0; optimum&#xC5D0; &#xAC00;&#xAE4C;&#xC774; &#xC788;&#xC744; &#xD655;&#xB960;&#xC774; &#xB192;&#xAE30; &#xB54C;&#xBB38;&#xC5D0; &#xC791;&#xC740; &#xD06C;&#xAE30;&#xB85C; &#xC774;&#xB3D9;&#xD558;&#xBA74;&#xC11C; &#xC138;&#xBC00;&#xD55C; &#xAC12;&#xC744; &#xC870;&#xC815;&#xD558;&#xACE0;, &#xC801;&#xAC8C; &#xBCC0;&#xD654;&#xD55C; &#xBCC0;&#xC218;&#xB4E4;&#xC740; optimum &#xAC12;&#xC5D0; &#xB3C4;&#xB2EC;&#xD558;&#xAE30; &#xC704;&#xD574;&#xC11C;&#xB294; &#xB9CE;&#xC774; &#xC774;&#xB3D9;&#xD574;&#xC57C;&#xD560; &#xD655;&#xB960;&#xC774; &#xB192;&#xAE30; &#xB54C;&#xBB38;&#xC5D0; &#xBA3C;&#xC800; &#xBE60;&#xB974;&#xAC8C; loss &#xAC12;&#xC744; &#xC904;&#xC774;&#xB294; &#xBC29;&#xD5A5;&#xC73C;&#xB85C; &#xC774;&#xB3D9;&#xD558;&#xB824;&#xB294; &#xBC29;&#xC2DD;&#xC774;&#xB77C;&#xACE0; &#xC0DD;&#xAC01;&#xD560; &#xC218; &#xC788;&#xB2E4;. &#xD2B9;&#xD788; word2vec&#xC5D0;&#xC11C; word representation&#xC744; &#xD559;&#xC2B5;&#xC2DC;&#xD0AC; &#xACBD;&#xC6B0; &#xB2E8;&#xC5B4;&#xC758; &#xB4F1;&#xC7A5; &#xD655;&#xB960;&#xC5D0; &#xB530;&#xB77C; &#xBCC0;&#xC218;&#xC758; &#xC0AC;&#xC6A9; &#xBE44;&#xC728;&#xC774; &#xD655;&#xC5F0;&#xD558;&#xAC8C; &#xCC28;&#xC774;&#xB098;&#xAE30; &#xB54C;&#xBB38;&#xC5D0; Adagrad&#xC640; &#xAC19;&#xC740; &#xD559;&#xC2B5;&#xBC29;&#xC2DD;&#xC744; &#xC774;&#xC6A9;&#xD558;&#xBA74; &#xD6E8;&#xC52C; &#xB354; &#xC88B;&#xC740; &#xC131;&#xB2A5;&#xC744; &#xB0BC; &#xC218;&#xC788;&#xB2E4;. </p>
<p>Adagrad&#xC758; &#xD55C; &#xC2A4;&#xD15D;&#xC744; &#xC218;&#xC2DD;&#xD654; &#xD558;&#xBA74; &#xB2E4;&#xC74C;&#xACFC; &#xAC19;&#xB2E4;.</p>
<p><script type="math/tex; mode=display">
G_{t} = G_{t-1} + (\nabla_{\theta}J(\theta_t))^2 \\
\theta_{t+1} = \theta_t - \frac{\eta}{\sqrt{G_t + \epsilon}} \cdot \nabla_{\theta}J(\theta_t)
</script></p>
<p>&#xC2E0;&#xACBD;&#xB9DD;&#xC758; &#xD30C;&#xB77C;&#xBBF8;&#xD130;&#xAC00; k&#xAC1C;&#xB77C;&#xACE0; &#xD560; &#xB54C;, <script type="math/tex; ">G_t</script> &#xB294; k&#xCC28;&#xC6D0; &#xBCA1;&#xD130;&#xB85C;&#xC11C; time step t&#xAE4C;&#xC9C0; &#xAC01; &#xBCC0;&#xC218;&#xAC00; &#xC774;&#xB3D9;&#xD55C; gradient&#xC758; &#xC81C;&#xACF1;&#xC744; &#xC800;&#xC7A5;&#xD55C;&#xB2E4;. <script type="math/tex; ">\theta</script> &#xB97C; &#xC5C5;&#xB370;&#xC774;&#xD2B8;&#xD558;&#xB294; &#xC0C1;&#xD669;&#xC5D0;&#xC11C;&#xB294; &#xAE30;&#xC874; step size <script type="math/tex; ">\eta</script> &#xC5D0; <script type="math/tex; ">G_t</script> &#xC758; &#xB8E8;&#xD2B8;&#xAC12;&#xC5D0; &#xBC18;&#xBE44;&#xB840;&#xD55C; &#xD06C;&#xAE30;&#xB85C; &#xC774;&#xB3D9;&#xC744; &#xC9C4;&#xD589;&#xD558;&#xC5EC; &#xC9C0;&#xAE08;&#xAE4C;&#xC9C0; &#xB9CE;&#xC774; &#xBCC0;&#xD654;&#xD55C; &#xBCC0;&#xC218;&#xC77C; &#xC218;&#xB85D; &#xC801;&#xAC8C; &#xC774;&#xB3D9;&#xD558;&#xACE0; &#xC801;&#xAC8C; &#xBCC0;&#xD654;&#xD55C; &#xBCC0;&#xC218;&#xC77C;&#xC218;&#xB85D; &#xB9CE;&#xC774; &#xC774;&#xB3D9;&#xD558;&#xB3C4;&#xB85D; &#xD55C;&#xB2E4;. &#xC774;&#xB54C; <script type="math/tex; ">\epsilon</script> &#xC740; <script type="math/tex; ">10^{-4}~10^{-8}</script> &#xC815;&#xB3C4;&#xC758; &#xC791;&#xC740;&#xAC12;&#xC73C;&#xB85C;&#xC11C; 0&#xC73C;&#xB85C; &#xB098;&#xB204;&#xB294; &#xAC83;&#xC744; &#xBC29;&#xC9C0;&#xD558;&#xAE30; &#xC704;&#xD55C; &#xC791;&#xC740; &#xAC12;&#xC774;&#xB2E4;. &#xC5EC;&#xAE30;&#xC5D0;&#xC11C; <script type="math/tex; ">G_t</script> &#xB97C; &#xC5C5;&#xB370;&#xC774;&#xD2B8;&#xD558;&#xB294; &#xC2DD;&#xC5D0;&#xC11C; &#xC81C;&#xACF1;&#xC740; element-wise(&#xB450; &#xBCA1;&#xD130;&#xC640; &#xD589;&#xB82C;&#xC5D0;&#xC11C; &#xAC19;&#xC740; &#xC704;&#xCE58;&#xC5D0; &#xC788;&#xB294; &#xC6D0;&#xC18C;&#xB07C;&#xB9AC; &#xB367;&#xC148;&#xACFC; &#xBE84;&#xC148;&#xC744; &#xD558;&#xBA74; &#xB41C;&#xB2E4;. &#xC774;&#xB7EC;&#xD55C; &#xC5F0;&#xC0B0;&#xC744; &#xC694;&#xC18C;&#xBCC4;(element-wise) &#xC5F0;&#xC0B0;)&#xC81C;&#xACF1;&#xC744; &#xC758;&#xBBF8;&#xD558;&#xBA70; <script type="math/tex; ">\theta</script> &#xB97C; &#xC5C5;&#xB370;&#xC774;&#xD2B8;&#xD558;&#xB294; &#xC2DD;&#xC5D0;&#xC11C;&#xB3C4; <script type="math/tex; ">\cdot</script> &#xC740; element-wise &#xC5F0;&#xC0B0;&#xC744; &#xC758;&#xBBF8;&#xD55C;&#xB2E4;.</p>
<p>Adagrad&#xB97C; &#xC0AC;&#xC6A9;&#xD558;&#xBA74; &#xD559;&#xC2B5;&#xC744; &#xC9C4;&#xD589;&#xD558;&#xBA74;&#xC11C; &#xAD73;&#xC774; step size decay&#xB4F1;&#xC744; &#xC2E0;&#xACBD;&#xC368;&#xC8FC;&#xC9C0; &#xC54A;&#xC544;&#xB3C4; &#xB41C;&#xB2E4;. &#xBCF4;&#xD1B5; adagrad&#xC5D0;&#xC11C; step size&#xB85C;&#xB294; 0.01 &#xC815;&#xB3C4;&#xB97C; &#xC0AC;&#xC6A9;&#xD55C; &#xB4A4;, &#xADF8; &#xC774;&#xD6C4;&#xB85C;&#xB294; &#xBC14;&#xAFB8;&#xC9C0; &#xC54A;&#xB294;&#xB2E4;. &#xADF8;&#xB7EC;&#xB098; Adagrad&#xC5D0;&#xB294; &#xD559;&#xC2B5;&#xC744; &#xACC4;&#xC18D; &#xC9C4;&#xD589;&#xD558;&#xBA74; G&#xC5D0;&#xB294; &#xACC4;&#xC18D; &#xC81C;&#xACF1;&#xD55C; &#xAC12;&#xC744; &#xB123;&#xC5B4;&#xC8FC;&#xAE30; &#xB54C;&#xBB38;&#xC5D0; G&#xC758; &#xAC12;&#xB4E4;&#xC740; &#xACC4;&#xC18D;&#xD574;&#xC11C; &#xC99D;&#xAC00;&#xD574;&#xC11C; &#xD559;&#xC2B5;&#xC744; &#xC624;&#xB798; &#xC9C4;&#xD589;&#xB420; &#xACBD;&#xC6B0; step size&#xAC00; &#xB108;&#xBB34; &#xC791;&#xC544;&#xC838;&#xC11C; &#xACB0;&#xAD6D; &#xAC70;&#xC758; &#xC6C0;&#xC9C1;&#xC774;&#xC9C0; &#xC54A;&#xAC8C; &#xB41C;&#xB2E4;. &#xC774;&#xB97C; &#xBCF4;&#xC644;&#xD558;&#xC5EC; &#xACE0;&#xCE5C; &#xC54C;&#xACE0;&#xB9AC;&#xC998;&#xC774; RMSProp&#xACFC; AdaDelta&#xC774;&#xB2E4;.</p>
<h4 id="rmsprop">RMSProp</h4>
<p>Adagrad&#xC758; &#xB2E8;&#xC810;&#xC744; &#xD574;&#xACB0;&#xD558;&#xAE30; &#xC704;&#xD55C; &#xBC29;&#xBC95;&#xC774;&#xB2E4;. Adagrad&#xC758; &#xC2DD;&#xC5D0;&#xC11C; gradient&#xC758; &#xC81C;&#xACF1;&#xAC12;&#xC744; &#xB354;&#xD574;&#xB098;&#xAC00;&#xBA74;&#xC11C; &#xAD6C;&#xD55C; <script type="math/tex; ">G_t</script> &#xBD80;&#xBD84;&#xC744; &#xD569;&#xC774;&#xC544;&#xB2C8;&#xB77C; &#xC9C0;&#xC218;&#xD3C9;&#xADE0;&#xC73C;&#xB85C; &#xBC14;&#xAFB8;&#xC5B4;&#xC11C; &#xB300;&#xCCB4;&#xD55C; &#xBC29;&#xBC95;&#xC774;&#xB2E4;. &#xC774;&#xB807;&#xAC8C; &#xB300;&#xCCB4;&#xB97C; &#xD560; &#xACBD;&#xC6B0; Adagrad&#xCC98;&#xB7FC; <script type="math/tex; ">G_t</script> &#xAC00; &#xBB34;&#xD55C;&#xC815; &#xCEE4;&#xC9C0;&#xC9C0; &#xC54A;&#xC73C;&#xBA74;&#xC11C; &#xCD5C;&#xADFC; &#xBCC0;&#xD654;&#xB7C9;&#xC758; &#xBCC0;&#xC218;&#xAC04; &#xC0C1;&#xB300;&#xC801;&#xC778; &#xD06C;&#xAE30; &#xCC28;&#xC774;&#xB294; &#xC720;&#xC9C0;&#xD560; &#xC218; &#xC788;&#xB2E4;. </p>
<p><script type="math/tex; mode=display">
G = \gamma G + (1-\gamma)(\nabla_{\theta}J(\theta_t))^2 \\
\theta = \theta - \frac{\eta}{\sqrt{G + \epsilon}} \cdot \nabla_{\theta}J(\theta_t)
</script></p>
<h4 id="adam-adaptive-moment-estimation">Adam (Adaptive Moment Estimation)</h4>
<p>RMSProp&#xACFC; Mementum &#xBC29;&#xC2DD;&#xC744; &#xD569;&#xCE5C; &#xAC83; &#xAC19;&#xC740; &#xC54C;&#xACE0;&#xB9AC;&#xC998;&#xC774;&#xB2E4;. Momentum &#xBC29;&#xC2DD;&#xACFC; &#xC720;&#xC0AC;&#xD558;&#xAC8C; &#xC9C0;&#xAE08;&#xAE4C;&#xC9C0; &#xACC4;&#xC0B0;&#xD574;&#xC628; &#xAE30;&#xC6B8;&#xAE30;&#xC758; &#xC9C0;&#xC218;&#xD3C9;&#xADE0;&#xC744; &#xC800;&#xC7A5;&#xD558;&#xBA70; RMSProp&#xACFC; &#xC720;&#xC0AC;&#xD558;&#xAC8C; &#xAE30;&#xC6B8;&#xAE30;&#xC758; &#xC81C;&#xACF1;&#xAC12;&#xC758; &#xC9C0;&#xC218;&#xD3C9;&#xADE0;&#xC744; &#xC800;&#xC7A5;&#xD55C;&#xB2E4;. </p>
<p><script type="math/tex; mode=display">
m_t = \beta_1 m_{t-1} + (1-\beta_1)\nabla_\theta J(\theta) \\
v_t = \beta_2 v_{t-1} + (1-\beta_2)(\nabla_\theta J(\theta))^2
</script></p>
<p>&#xB2E4;&#xB9CC; Adam&#xC5D0;&#xC11C;&#xB294; m,v&#xAC00; &#xCC98;&#xC74C;&#xC5D0; 0&#xC73C;&#xB85C; &#xCD08;&#xAE30;&#xD654;&#xB418;&#xC5B4; &#xC788;&#xAE30; &#xB54C;&#xBB38;&#xC5D0; &#xD559;&#xC2B5; &#xCD08;&#xBC18;&#xBD80;&#xC5D0;&#xC11C;&#xB294; <script type="math/tex; ">m_t,v_t</script> &#xAC00; 0&#xC5D0; &#xAC00;&#xAE5D;&#xAC8C; bias &#xB418;&#xC5B4;&#xC788;&#xC744; &#xAC83;&#xC774;&#xB77C;&#xACE0; &#xD310;&#xB2E8;&#xD558;&#xC5EC; &#xC774;&#xB97C; unbiased&#xD558;&#xAC8C; &#xB9CC;&#xB4E4;&#xC5B4;&#xC8FC;&#xB294; &#xC791;&#xC5C5;&#xC744; &#xAC70;&#xCE5C;&#xB2E4;. <script type="math/tex; ">m_t, v_t</script> &#xC758; &#xC2DD;&#xC744; <script type="math/tex; ">\sum</script> &#xD615;&#xD0DC;&#xB85C; &#xD3BC;&#xCE5C; &#xD6C4; &#xC591;&#xBCC0;&#xC5D0; &#xAE30;&#xB313;&#xAC12;(expectation)&#xC744; &#xC50C;&#xC6CC;&#xC11C; &#xC815;&#xB9AC;&#xD558;&#xBA74; unbiased&#xB41C; &#xAE30;&#xB313;&#xAC12;&#xC744; &#xC5BB;&#xC744; &#xC218; &#xC788;&#xB2E4;. gradient&#xAC00; &#xB4E4;&#xC5B4;&#xAC08; &#xC790;&#xB9AC;&#xC5D0; <script type="math/tex; ">\hat m_t</script> <script type="math/tex; ">G_t</script> &#xAC00; &#xB4E4;&#xC5B4;&#xAC08; &#xC790;&#xB9AC;&#xC5D0; <script type="math/tex; ">\hat v_t</script> &#xB97C; &#xB123;&#xC5B4; &#xACC4;&#xC0B0;&#xC744; &#xC9C4;&#xD589;&#xD55C;&#xB2E4;. </p>
<p><script type="math/tex; mode=display">
\hat m_t = \dfrac {m_t}{1-\beta^t_1} \\
\hat v_t = \dfrac {v_t}{1-\beta^t_2} \\
\theta = \theta - \frac{\eta}{\sqrt{\hat{v_t}+\epsilon}}\hat{m_t}
</script></p>
<p>&#xBCF4;&#xD1B5; <script type="math/tex; ">\beta_1</script> &#xB85C;&#xB294; 0.9, <script type="math/tex; ">\beta_2</script> &#xB85C;&#xB294; 0.999, <script type="math/tex; ">\epsilon</script> &#xC73C;&#xB85C;&#xB294; <script type="math/tex; ">10^{-8}</script> &#xC815;&#xB3C4;&#xC758; &#xAC12;&#xC744; &#xC0AC;&#xC6A9;&#xD55C;&#xB2E4;&#xACE0; &#xD55C;&#xB2E4;. </p>
<h4 id="etc">etc</h4>
<p>&#xC704;&#xC5D0;&#xC11C; &#xC124;&#xBA85;&#xD55C; &#xC54C;&#xACE0;&#xB9AC;&#xC998;&#xB4E4;&#xC740; SGD&#xB85C; &#xB2E8;&#xC21C;&#xD55C; first-order optimization&#xC758; &#xBCC0;&#xD615;&#xB4E4;&#xC774;&#xB2E4;. &#xC774;&#xC678;&#xC5D0;&#xB3C4; Newton&apos;s Method&#xB4F1; second-order optimizaion&#xC744; &#xAE30;&#xBC18;&#xC73C;&#xB85C; &#xD55C; &#xC54C;&#xACE0;&#xB9AC;&#xC998;&#xB4E4;&#xB3C4; &#xC788;&#xB2E4;. &#xB2E8;&#xC21C;&#xD55C; second-order optimizaion&#xC744; &#xC0AC;&#xC6A9;&#xD558;&#xAE30; &#xC704;&#xD574;&#xC11C;&#xB294; Hessian Matrix&#xB77C;&#xB294; 2&#xCC28; &#xD3B8;&#xBBF8;&#xBD84; &#xD589;&#xB82C;&#xC744; &#xACC4;&#xC0B0;&#xD55C; &#xD6C4; &#xC5ED;&#xD589;&#xB82C;&#xC744; &#xAD6C;&#xD574;&#xC57C;&#xB294;&#xB370; &#xACC4;&#xC0B0;&#xACFC;&#xC815;&#xC774; &#xBE44;&#xC2FC; &#xC791;&#xC5C5;&#xC774;&#xC5EC;&#xC11C; &#xBCF4;&#xD1B5; &#xC798; &#xC0AC;&#xC6A9;&#xB418;&#xC9C0; &#xC54A;&#xB294;&#xB2E4;. &#xC774;&#xB7EC;&#xD55C; &#xACC4;&#xC0B0;&#xB7C9;&#xC744; &#xC904;&#xC774;&#xAE30; &#xC704;&#xD574; hessian matrix&#xB97C; &#xADFC;&#xC0AC;&#xD558;&#xAC70;&#xB098; &#xCD94;&#xC815;&#xD574;&#xB098;&#xAC00;&#xBA74;&#xC11C; &#xACC4;&#xC0B0;&#xC744; &#xC9C4;&#xD589;&#xD558;&#xB294; BFGS/L-BFGS &#xB4F1;&#xC758; &#xC54C;&#xACE0;&#xB9AC;&#xC998;, &#xADF8;&#xB9AC;&#xACE0; hessian matrix&#xB97C; &#xC9C1;&#xC811; &#xACC4;&#xC0B0;&#xD558;&#xC9C0; &#xC54A;&#xC73C;&#xBA74;&#xC11C; second-order optimization&#xC778; Hessian-Free Optimization &#xB4F1;&#xB3C4; &#xC874;&#xC7AC;&#xD55C;&#xB2E4;.</p>
<p>Reference</p>
<ul>
<li><a href="https://datascienceschool.net/" target="_blank">https://datascienceschool.net/</a></li>
<li><a href="http://shuuki4.github.io/deep%20learning/2016/05/20/Gradient-Descent-Algorithm-Overview.html" target="_blank">http://shuuki4.github.io/deep%20learning/2016/05/20/Gradient-Descent-Algorithm-Overview.html</a></li>
</ul>

                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="04neuralnetwork-optimization.html" class="navigation navigation-prev " aria-label="Previous page: 신경망 최적화 방법">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
                <a href="cnn/" class="navigation navigation-next " aria-label="Next page: CNN">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"그레디언트 최적화 알고리즘 요약","level":"1.6.5","depth":2,"next":{"title":"CNN","level":"1.6.6","depth":2,"path":"posts/deeplearning/cnn/README.md","ref":"posts/deeplearning/cnn/README.md","articles":[{"title":"CNN","level":"1.6.6.1","depth":3,"path":"posts/deeplearning/cnn/00cnn.md","ref":"posts/deeplearning/cnn/00cnn.md","articles":[]},{"title":"AlexNet","level":"1.6.6.2","depth":3,"path":"posts/deeplearning/cnn/01alexnet.md","ref":"posts/deeplearning/cnn/01alexnet.md","articles":[]},{"title":"GooLeNet","level":"1.6.6.3","depth":3,"path":"posts/deeplearning/cnn/02googlenet.md","ref":"posts/deeplearning/cnn/02googlenet.md","articles":[]},{"title":"ResNet","level":"1.6.6.4","depth":3,"path":"posts/deeplearning/cnn/03resnet.md","ref":"posts/deeplearning/cnn/03resnet.md","articles":[]},{"title":"DanseNet","level":"1.6.6.5","depth":3,"path":"posts/deeplearning/cnn/04densenet.md","ref":"posts/deeplearning/cnn/04densenet.md","articles":[]}]},"previous":{"title":"신경망 최적화 방법","level":"1.6.4","depth":2,"path":"posts/deeplearning/04neuralnetwork-optimization.md","ref":"posts/deeplearning/04neuralnetwork-optimization.md","articles":[]},"dir":"ltr"},"config":{"gitbook":"*","theme":"default","variables":{},"plugins":["mathjax","collapsible-menu","etoc","splitter"],"pluginsConfig":{"collapsible-menu":{},"etoc":{"h2lb":3,"header":1,"maxdepth":4,"mindepth":3,"notoc":false},"splitter":{},"search":{},"lunr":{"maxIndexSize":1000000,"ignoreSpecialCharacters":false},"fontsettings":{"theme":"white","family":"sans","size":2},"highlight":{},"mathjax":{"forceSVG":false,"version":"2.6-latest"},"sharing":{"facebook":true,"twitter":true,"google":false,"weibo":false,"instapaper":false,"vk":false,"all":["facebook","google","twitter","weibo","instapaper"]},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false}},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56}},"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"}},"file":{"path":"posts/deeplearning/gd-algorithem.md","mtime":"2020-04-09T07:07:48.640Z","type":"markdown"},"gitbook":{"version":"3.2.3","time":"2020-04-09T16:48:43.034Z"},"basePath":"../..","book":{"language":""}});
        });
    </script>
</div>

        
    <script src="../../gitbook/gitbook.js"></script>
    <script src="../../gitbook/theme.js"></script>
    
        
        <script src="https://cdn.mathjax.org/mathjax/2.6-latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
        
    
        
        <script src="../../gitbook/gitbook-plugin-mathjax/plugin.js"></script>
        
    
        
        <script src="../../gitbook/gitbook-plugin-collapsible-menu/plugin.js"></script>
        
    
        
        <script src="../../gitbook/gitbook-plugin-etoc/plugin.js"></script>
        
    
        
        <script src="../../gitbook/gitbook-plugin-splitter/splitter.js"></script>
        
    
        
        <script src="../../gitbook/gitbook-plugin-search/search-engine.js"></script>
        
    
        
        <script src="../../gitbook/gitbook-plugin-search/search.js"></script>
        
    
        
        <script src="../../gitbook/gitbook-plugin-lunr/lunr.min.js"></script>
        
    
        
        <script src="../../gitbook/gitbook-plugin-lunr/search-lunr.js"></script>
        
    
        
        <script src="../../gitbook/gitbook-plugin-sharing/buttons.js"></script>
        
    
        
        <script src="../../gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    

    </body>
</html>

