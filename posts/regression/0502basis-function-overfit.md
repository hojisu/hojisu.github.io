<script> MathJax.Hub.Queue(["Typeset",MathJax.Hub]); </script>

# 기저함수 모형과 과최적화

### Summary
- 기저함수는 특정한 규칙에 따라 만들어지는 함수의 시퀀스로 충분히 많은 수의 함수가 있으면 어떤 모양의 함수로도 비슷하게 흉내낼 수 있다. 다항기저함수를 사용한 다항회귀 모형이 있다.
- 과최적화는 특정샘플에 대해 과도하게 최적화된 것을 말한다. 샘플이 조금만 변화해도 가중치의 계수의 값이 크게 달라진다. 새로운 독립 변수 값을 입력하면 오차가 커진다
_____________________________

### 비선형 모형

데이터가 비선형일 경우 독립변수 벡터 x를 입력으로 가지는 여러개의 비선형 함수 $$\phi_j(x)$$ 들을 생각해내어 원래의 입력 변수 x대신 $$\phi_j(x)$$ 들을 입력변수로 사용하여 다음과 같은 모형을 쓰면 더 좋은 예측 성능을 가질 수 있다. 이 새로운 모형의 모수의 갯수는 원래의 독립변수의 갯수가 아니라 우리가 생각해 낸 **비선형 함수의 갯수에 의존**한다.
  
$$
y_i = \sum_{j=1}^{M} w_j \phi_j(x)  = w^T \phi(x)
$$


### 기저함수(basis function)

특정한 규칙에 따라 만들어지는 함수의 열(sequence)로서 충분히 많은 수의 함수가 있으며 어떤 모양의 함수라도 비슷하게 흉내낼 수 있는 것을 말한다. 

#### 다항 기저함수(polynomial basis function)

$$\phi_0(x) = 1, \phi_1(x) = x, \phi_2(x) = x^2, \phi_3(x) = x^3, \cdots$$

#### 다항회귀(ploynomial regression) 

다항 기저함수를 사용하는 기저함수 모형이다. 

$$y = w_0 + w_1x + w_2x^2  + \ldots  + w_M x^M$$

기저함수중에서도 서로 다른 두 기저함수의 곱의 정적분 값이 0이 되면 직교기저함수(orthogonal basis function) 라고 한다. (예: 체비세프 다항식)

#### StatsModels를 이용한 다항회귀

StatsModels에서는 `OLS` 클래스의 `from_formula` 메서드를 사용하여 다항회귀를 할 수 있다.

~~~python
sm.OLS.from_formula("y ~ x", data=df).fit().summary()
sm.OLS.from_formula("y ~ x + I(x**2)", data=df).fit().summary()sm.OLS.from_formula("y ~ x + I(x**2) + I(x**3)", data=df).fit().summary()
~~~

### 과최적화

모형을 특정 샘플 데이터에 대해 과도하게 최적화하는 것을 과최적화(overfitting)이라고 한다.
- 독립 변수 데이터 갯수에 비해 모형 모수의 수가 과도하게 크거나 독립 변수 데이터가 서로 독립이 아닌 경우에 발생한다. 

과최적화가 문제가 되는 이유
- 트레이닝에 사용되지 않은 새로운 독립 변수 값을 입력하면 오차가 커진다(**cross-validation 오차**)
- 샘플이 조금만 변화해도 가중치의 계수의 값이 크게 달라진다.(추정의 부정확함)